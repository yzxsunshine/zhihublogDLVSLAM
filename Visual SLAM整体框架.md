# Visual SLAM整体框架
Visual SLAM大致可以翻译为基于视觉(Visual)的同步**摄像机定位**与**地图重建**（**S**imultaneously **L**ocalization **a**nd **M**apping），属于SLAM技术的一个分支。早期的SLAM技术大多应用在机器人领域，通过机器人上的雷达和GPS等定位、测距传感器，构建2D地图的同时完成机器人自身的定位。而如今随着各类传感器的出现和发展，基于视觉的SLAM技术因为图像信息方便、丰富、精准等原因成为主流之一，应用场景包括增强现实/虚拟现实头部跟踪、机器人导航、无人驾驶车、无人飞行器等等。SLAM这一技术的主要难点就在“同时”这个词上。在系统初始阶段，场景和系统姿态都是为未知信息。地图信息来源于相机姿态和场景特征，同时相机姿态有需要用地图信息来计算。有些类似鸡生蛋蛋生鸡的悖论（注：也挺像太极的(´・ω・｀)，见图1）。SLAM技术的核心就在与提取建立场景和系统之间的约束，通过解这些约束逐步恢复场景和系统姿态。

<img src="https://github.com/yzxsunshine/zhihublogDLVSLAM/blob/master/taichi_cat.png" alt="太极猫" width="200px"/>

图1

早期的Visual SLAM技术并没有明确的前端和后端概念，系统姿态估计和场景标记（Landmark）维护都会在一帧内完成。结果就是要么约束优化时引入无用的标记，每一帧的效率比较低；要么只使用新建立的标记，系统误差不断累积下去。

近十几年起，Visual SLAM技术经过逐渐的打磨，系统框架逐渐稳定了下来。一般的Visual SLAM系统大致上会有前端和后端之分。前端主要负责每一帧的姿态估计（Pose Estimation），并且在姿态估计完成后不断地往地图（Map）中添加约束；后端主要负责把收集到的约束进行（图）优化，并把优化完的结果反馈给前端。一般意义上的实时Visual SLAM系统指得都是前端实时，但是后端因为计算量庞大，所以一般都是隔几帧更新一次。平时大家说的Visual SLAM前端通常都有特征提取，特征匹配等过程，后端一般是联合优化（Bundle Adjustment）以及相机姿态图优化（Pose Graph Optimization）。但实际上前后端的技术们有各种各样的分类方法。我会在之后的文章里进行一一介绍。

接下来谈一些个人心得。Visual SLAM这个行业入门门槛高，可以说对新人非常不友好(ง •̀_•́)ง┻━┻。相机姿态和地图构建这一对鸡生蛋蛋生鸡的高耦合冤家决定了整个系统的每一个环节都必须全力以赴不能马虎。比如，前端因为计算力不足，算法不够优化导致帧率不高，那给后端的约束数量和质量就会下降，反过来给前端的姿态估计带来更多麻烦。因此，要从事Visual SLAM这个行业就需要比较好的工程能力和经验，愿意去打磨一些细节。如果要从事Visual SLAM的研究，虽然可以有诸多开源框架可以使用（比如ORBSLAM），但是如果对一些细节不了解的话，很难找到合适的研究点。真·细节决定成败（ლ(⁰⊖⁰ლ)）。

最后祝您和Visual SLAM玩的愉快，与诸君共勉。
