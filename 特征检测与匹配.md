# Visual SLAM前端技术 - 特征检测与匹配
在这一篇，我将简要地介绍一些稀疏方法中的特征检测与匹配技术。特征检测与匹配，除了Visual SLAM外，同时也是物体检测、跟踪等方向非常重要的基础技术。特征检测技术解决的是在图像中提取“有意义”的点。这里有意义通常是指一些图像空间的边角特征点。就以人类的角度来说，一些色彩剧烈变化的位置（几何或阴影边缘，材质纹理的边角）当然会比大白墙上平平无奇的白点要更容易引起注意。而特征匹配技术要解决的是在给定两张或以上的图片时找到图片中特征点的匹配关系，从而判断出图像的哪一些区域是相似的。在深度学习席卷机器视觉领域之前，研究者们不断地提出新的人工特征检测子(detector)和描述子(descriptor)。而衡量这些技术时有几个重要考量因素：特征点精度（亚像素/像素）、旋转不变性、光照不变性、缩放不变性、特征提取速度。下面我先来举几个例子讲一下特征检测的相关技术。
# 特征检测 —— 角点定位
## FAST算法
FAST[1]可以算是最简单的特征检测算法了。FAST算法主要包括三个步骤：角点初步筛选，ID3分类筛选，非最大值抑制。在焦点初步筛选过程中，FAST算法在备选角点p周围一圈16个殿中需按照连续n（例如n=12）个灰度皆高于或低于p自身灰度的点。初步筛选出来的角点基本囊括了图像中的尖锐角点，但同时也有选出很多非最优点、角点连在一起等问题。这些问题都可以通过训练一个ID3分类器以及非最大抑制来进行进一步优化得到最终的优质角点。具体的细节可以参考这篇博客 (https://blog.csdn.net/ssw_1990/article/details/70569871) 以及OpenCV的官方文档 (https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_fast/py_fast.html) 。FAST算法的有点就是非常快，如果环境和相机位置差别不大的情况下，点的质量也算不错，稍加改造加上图像金字塔处理后就能一定程度解决缩放不变性的问题。因此很受实时Visual SLAM系统的欢迎，比如PTAM。
图1 https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e/5-Figure1-1.png

## Harris算法
相比FAST算法的简单粗暴，Harris算法[2]更偏向于从物理角度理解和提取角点。处理每个像素时，Harris算法会在局部领域（滑动窗口）范围内计算该像素和领域内其他像素的灰度自相关性。当该像素往任意方向移动时都没有明显灰度变化时，该像素没有提取价值；当只有在某一方向移动无明显灰度变化时，该像素是一个边缘点；当任意方向都有剧烈灰度变化时，该像素就是一个好的角点。而如果对自相关性矩阵求特征值和特征向量，得到的两个特征值$\lambda_1$和$\lambda_2$便可以用来描述前面说的灰度变化属性。原Harris算法文章中用了$\lambda_1\lambda_2 - k(\lambda_1 + \lambda_2)^2 > threshold$，而在Good Features To Track[3]这篇文章中则简化为$min(\lambda_1, \lambda_2) > threshold$并得到更好的角点提取结果。

## SIFT算法（角点定位）
上述两种角点检测算法都能够很好地从图像中提取出显著的特征点，并且由于利用的是相对灰度或灰度上的梯度，这两种方法都对光照变化不是那么敏感（剧烈变化还是有很大影响的）。但要用于任意两张图像特征点匹配，此类方法则会显得力不从心。要解决任意两张图象特征匹配，那么在特征点检测阶段就需要考虑到尺度不变性、旋转不变性。David Lowe提出的SIFT算法[4] 便是专门设计出来解决这些问题的。
要达到尺度不变首先要了解尺度空间的特性。图像在尺度空间的变化接近于不断对图像使用高斯卷积。那么不同尺度的图像之间的区别就可以用不同高斯核卷积后的差分图像代替。差分高斯空间（Difference of Gaussian scale space)就是这么产生的。在DoG的基础上，Lowe进一步做了DoG金字塔，并在每一层中采用局部极值的方法来提取出各个尺度上对尺度变化不敏感的备选特征点。在计算局部极值时，每个点需要和本张图片的周围八个邻点以及同层上下两张图像的各九个点做对比，保证其在图像空间和尺度空间都是极大或极小值。剔除一些边缘点（类似Harris过程），SIFT特征点便生成出来了。

# 特征检测 —— 特征点描述子提取
## 邻域模板匹配
特征描述子（Descriptor）指的是用于描述每个特征点信息的数据结构。由于描述子是特征匹配中的必要输入，因此描述子当然是越能代表特征点的“特征”越好。最简单的描述子就是特征点附近邻域窗口内的像素灰度信息了。用邻域灰度信息来做匹配也就是邻域模板匹配。逐像素的模板匹配方法通常有SSD（Sum of Squared Difference 平方距离和），NCC（Normalized Cross Correlation归一化交叉相关）等。模板匹配在图像变化不大且大概知道目标点范围时非常好用。只需要在目标点范围内做滑动窗口匹配即可。如果是相邻两帧图像，那么模板匹配是个不错的选择。但当图像的光照、缩放或旋转发生剧烈变化，又或者图像相隔帧数过多，无法给定有效目标匹配范围时，模板匹配不仅耗时且效果奇差。

## SIFT特征描述子
为了解决模板匹配的问题，SIFT的描述子采用了灰度梯度（光照变化不敏感）的方向（旋转不变）直方图（对噪声不敏感）。SIFT在特征点附近16x16个像素以4x4为单位计算灰度梯度方向的直方图（包含8个主方向）。然后将这些梯度方向的坐标轴旋转到关键点的梯度主方向从而确保旋转不变。而这4x4x8的直方图就成为初步的SIFT特征描述子。在进一步对这些特征进行归一化减少亮度影响后，就是最终的SIFT特征描述子了。

## ORB特征描述子
SIFT特征描述子虽然十分强大，但是同时计算时间也较长，描述子要占用128个FLOAT空间（也有64位整型版本，效果自然差一些）。BRIEF算法[5]采用了二进制的描述子试图解决上述问题。BRIEF算法在特征点SxS的邻域内随机选取N对点(x_i, y_i)进行灰度值对比，如果I(x_i)>I(y_i)则在特征位i为1，反之为0。这样便可以很快得到N位的二进制。但BRIEF因为之匹配点对，所以对噪声比较敏感，同时也不具备旋转不变性。ORB[6]在BRIEF的基础上，将点对匹配改为点对领域匹配，降低噪声的影响。同时在提取角点时，ORB会计算角点的灰度梯度主方向，在提取特征时将邻域窗口旋转到主方向上解决旋转变化的问题。ORB在完成这些改进后，性价比大幅提升，成为很多SLAM算法的必选特征描述子，比如ORBSLAM[7]。

# 特征匹配
暴力匹配
Kd树
语义树

# 参考文献
[1] Rosten, Edward, Reid Porter, and Tom Drummond. "Faster and better: A machine learning approach to corner detection." IEEE transactions on pattern analysis and machine intelligence 32.1 (2010): 105-119.
[2] Harris, Chris, and Mike Stephens. "A combined corner and edge detector." Alvey vision conference. Vol. 15. No. 50. 1988.
[3] Jianbo Shi and Carlo Tomasi. 1993. Good Features to Track. Technical Report. Cornell University, Ithaca, NY, USA.
[4] Lowe, David G. "Distinctive image features from scale-invariant keypoints." International journal of computer vision 60.2 (2004): 91-110.
[5] Calonder, Michael, et al. "Brief: Binary robust independent elementary features." European conference on computer vision. Springer, Berlin, Heidelberg, 2010.
[6] Rublee, Ethan, et al. "ORB: An efficient alternative to SIFT or SURF." Computer Vision (ICCV), 2011 IEEE international conference on. IEEE, 2011.
[7] Mur-Artal, Raul, Jose Maria Martinez Montiel, and Juan D. Tardos. "ORB-SLAM: a versatile and accurate monocular SLAM system." IEEE Transactions on Robotics 31.5 (2015): 1147-1163.