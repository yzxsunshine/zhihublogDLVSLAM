# Visual SLAM前端技术 - 特征检测与匹配
在这一篇，我将简要地介绍一些稀疏方法中的特征检测与匹配技术。特征检测与匹配，除了Visual SLAM外，同时也是物体检测、跟踪等方向非常重要的基础技术。特征检测技术解决的是在图像中提取“有意义”的点。这里有意义通常是指一些图像空间的边角特征点。就以人类的角度来说，一些色彩剧烈变化的位置（几何或阴影边缘，材质纹理的边角）当然会比大白墙上平平无奇的白点要更容易引起注意。而特征匹配技术要解决的是在给定两张或以上的图片时找到图片中特征点的匹配关系，从而判断出图像的哪一些区域是相似的。在深度学习席卷机器视觉领域之前，研究者们不断地提出新的人工特征检测子(detector)和描述子(descriptor)。而衡量这些技术时有几个重要考量因素：特征点精度（亚像素/像素）、旋转不变性、光照不变性、缩放不变性、特征提取速度。下面我先来举几个例子讲一下特征检测的相关技术。
# 特征检测 —— 角点定位
## FAST算法
FAST[1]可以算是最简单的特征检测算法了。FAST算法主要包括三个步骤：角点初步筛选，ID3分类筛选，非最大值抑制。在焦点初步筛选过程中，FAST算法在备选角点p周围一圈16个殿中需按照连续n（例如n=12）个灰度皆高于或低于p自身灰度的点。初步筛选出来的角点基本囊括了图像中的尖锐角点，但同时也有选出很多非最优点、角点连在一起等问题。这些问题都可以通过训练一个ID3分类器以及非最大抑制来进行进一步优化得到最终的优质角点。具体的细节可以参考这篇博客 (https://blog.csdn.net/ssw_1990/article/details/70569871) 以及OpenCV的官方文档 (https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_fast/py_fast.html) 。FAST算法的有点就是非常快，如果环境和相机位置差别不大的情况下，点的质量也算不错，稍加改造加上图像金字塔处理后就能一定程度解决缩放不变性的问题。因此很受实时Visual SLAM系统的欢迎，比如PTAM。
图1 https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e/5-Figure1-1.png

## Harris算法
相比FAST算法的简单粗暴，Harris算法[2]更偏向于从物理角度理解和提取角点。处理每个像素时，Harris算法会在局部领域（滑动窗口）范围内计算该像素和领域内其他像素的灰度自相关性。当该像素往任意方向移动时都没有明显灰度变化时，该像素没有提取价值；当只有在某一方向移动无明显灰度变化时，该像素是一个边缘点；当任意方向都有剧烈灰度变化时，该像素就是一个好的角点。而如果对自相关性矩阵求特征值和特征向量，得到的两个特征值$\lambda_1$和$\lambda_2$便可以用来描述前面说的灰度变化属性。原Harris算法文章中用了$\lambda_1\lambda_2 - k(\lambda_1 + \lambda_2)^2 > threshold$，而在Good Features To Track[3]这篇文章中则简化为$min(\lambda_1, \lambda_2) > threshold$并得到更好的角点提取结果。

## SIFT算法（角点定位）
上述两种角点检测算法都能够很好地从图像中提取出显著的特征点，并且由于利用的是相对灰度或灰度上的梯度，这两种方法都对光照变化不是那么敏感（剧烈变化还是有很大影响的）。但要用于任意两张图像特征点匹配，此类方法则会显得力不从心。要解决任意两张图象特征匹配，那么在特征点检测阶段就需要考虑到尺度不变性、旋转不变性。David Lowe提出的SIFT算法[4] 便是专门设计出来解决这些问题的。
要达到尺度不变首先要了解尺度空间的特性。图像在尺度空间的变化接近于不断对图像使用高斯卷积。那么不同尺度的图像之间的区别就可以用不同高斯核卷积后的差分图像代替。差分高斯空间（Difference of Gaussian scale space)就是这么产生的。在DoG的基础上，Lowe进一步做了DoG金字塔，并在每一层中采用局部极值的方法来提取出各个尺度上对尺度变化不敏感的备选特征点。在计算局部极值时，每个点需要和本张图片的周围八个邻点以及同层上下两张图像的各九个点做对比，保证其在图像空间和尺度空间都是极大或极小值。剔除一些边缘点（类似Harris过程），SIFT特征点便生成出来了。

# 特征检测 —— 特征点描述子提取
## 邻域模板匹配
特征描述子（Descriptor）指的是用于描述每个特征点信息的数据结构。由于描述子是特征匹配中的必要输入，因此描述子当然是越能代表特征点的“特征”越好。最简单的描述子就是特征点附近邻域窗口内的像素灰度信息了。用邻域灰度信息来做匹配也就是邻域模板匹配。逐像素的模板匹配方法通常有SSD（Sum of Squared Difference 平方距离和），NCC（Normalized Cross Correlation归一化交叉相关）等。模板匹配在图像变化不大且大概知道目标点范围时非常好用。只需要在目标点范围内做滑动窗口匹配即可。如果是相邻两帧图像，那么模板匹配是个不错的选择。但当图像的光照、缩放或旋转发生剧烈变化，又或者图像相隔帧数过多，无法给定有效目标匹配范围时，模板匹配不仅耗时且效果奇差。

## SIFT特征描述子
为了解决模板匹配的问题，SIFT的描述子采用了灰度梯度（光照变化不敏感）的方向（旋转不变）直方图（对噪声不敏感）。SIFT在特征点附近16x16个像素以4x4为单位计算灰度梯度方向的直方图（包含8个主方向）。然后将这些梯度方向的坐标轴旋转到关键点的梯度主方向从而确保旋转不变。而这4x4x8的直方图就成为初步的SIFT特征描述子。在进一步对这些特征进行归一化减少亮度影响后，就是最终的SIFT特征描述子了。

## ORB特征描述子
SIFT特征描述子虽然十分强大，但是同时计算时间也较长，描述子要占用128个FLOAT空间（也有64位整型版本，效果自然差一些）。BRIEF算法[5]采用了二进制的描述子试图解决上述问题。BRIEF算法在特征点SxS的邻域内随机选取N对点(x_i, y_i)进行灰度值对比，如果I(x_i)>I(y_i)则在特征位i为1，反之为0。这样便可以很快得到N位的二进制。但BRIEF因为之匹配点对，所以对噪声比较敏感，同时也不具备旋转不变性。ORB[6]在BRIEF的基础上，将点对匹配改为点对领域匹配，降低噪声的影响。同时在提取角点时，ORB会计算角点的灰度梯度主方向，在提取特征时将邻域窗口旋转到主方向上解决旋转变化的问题。ORB在完成这些改进后，性价比大幅提升，成为很多SLAM算法的必选特征描述子，比如ORBSLAM[7]。

# 特征匹配
## 暴力匹配
在提取出特征点的描述子后，下一步便是在两张图中进行特征点的匹配了。包括领域模板在内，每一种描述子都可以表示为一个1xN的特征向量。而最简单的办法就是将参照图中的每一个特征点挨个和目标图中的所有特征点的特征向量进行对比，然后取出差异最小的特征点做为匹配对。在计算两个特征向量差异时，如果是类型为浮点型或整形的特征向量，欧式距离是一个不错的选择；如果是二进制特征向量的话，要用汉明距离来计算。这种暴力匹配的方式当然需要比较大的计算量，是O(N^2)的时间复杂度。再考虑到实际应用时，经常会有多个点匹配的目标点相同的情况，因此一般都要将参照图和目标图调换一下再做一次交叉匹配（Cross Matching）。只有两次都匹配成功的点对才会被最终采用。

## Kd树
很明显暴力匹配在计算量和计算时间上很不现实。特别是在做摄像机重定位时要与地图中所有的关键帧进行匹配，暴力匹配就不要考虑了。因此通常需要对这些特征点描述子集中建立索引。K-dimensional Tree（Kd树）是一种常用的建立特征向量索引的方法。建立Kd树时，要不断地选取切分维度（当前子集内的所有点之间方差最大的维度），然后确定切分位置（按照切分维度排序选择中位数）。这方面已经有比较成熟的代码库可以使用，例如FLANN。FLANN既可以单独使用，同时也被集成到了OpenCV、PCL等代码库中。根据特征向量建立好Kd树后，查找Kd树中的最近邻居（K Nearest Neighbor）便可以得到目标图中匹配的特征点了。同样，使用Kd树时将参照图和目标图调换做交叉匹配。

除了在图像中使用Kd树加快两帧之间的特征匹配外，Kd树也可以建在地图点云相对应的特征向量上。每个三维点在加入全局地图时，都可以绑定一个或多个对应关键帧的描述子（从相应的二维特征点中提取）。通过将这些特征向量组织起来建立索引，便可以进行简单快速的摄像机重定位了。

## 语义树
上面简单提到了用Kd树建立的地图点云索引做摄像机重定位，这种方法只能在点云数量比较小的情况下进行。当点的数量增加时（例如室外场景），Kd树所占的内存和相应的检索时间都会变得难以接受。这个时候就要用语义树来建立地图点云索引。在使用时先用当前图片的特征描述子们找到最匹配的关键帧，然后再进行帧与帧之间的进一步匹配。具体的语义树实现方法我会在后端技术中再进行详细介绍。

# 参考文献
[1] Rosten, Edward, Reid Porter, and Tom Drummond. "Faster and better: A machine learning approach to corner detection." IEEE transactions on pattern analysis and machine intelligence 32.1 (2010): 105-119.
[2] Harris, Chris, and Mike Stephens. "A combined corner and edge detector." Alvey vision conference. Vol. 15. No. 50. 1988.
[3] Jianbo Shi and Carlo Tomasi. 1993. Good Features to Track. Technical Report. Cornell University, Ithaca, NY, USA.
[4] Lowe, David G. "Distinctive image features from scale-invariant keypoints." International journal of computer vision 60.2 (2004): 91-110.
[5] Calonder, Michael, et al. "Brief: Binary robust independent elementary features." European conference on computer vision. Springer, Berlin, Heidelberg, 2010.
[6] Rublee, Ethan, et al. "ORB: An efficient alternative to SIFT or SURF." Computer Vision (ICCV), 2011 IEEE international conference on. IEEE, 2011.
[7] Mur-Artal, Raul, Jose Maria Martinez Montiel, and Juan D. Tardos. "ORB-SLAM: a versatile and accurate monocular SLAM system." IEEE Transactions on Robotics 31.5 (2015): 1147-1163.